{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OaNumNOvPkn"
   },
   "source": [
    "# Introdução (Código - TG \"AVALIAÇÃO E APLICAÇÕES DE ALGORITMOS DE MACHINE LEARNING SOBRE PARTIDAS DE FUTEBOL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0g3zTO-vVl9"
   },
   "source": [
    "O mundo do futebol, um esporte globalmente aclamado, oferece vastas oportunidades para análises e insights valiosos por meio de técnicas de aprendizado de máquina. Neste projeto, explorou-se a aplicação dessas técnicas para analisar e classificar os resultados de partidas de futebol, com base em dados detalhados das temporadas de 2014 a 2017 obtidos através da plataforma \"Kaggle\".\n",
    "\n",
    "Os conjuntos de dados abrangentes incluem informações sobre jogadores, clubes e resultados de partidas, levando em consideração variáveis como gols marcados, aproveitamento como mandante e visitante, número de gols, entre outros fatores determinantes (features), calculados posteriormente. Ao longo da implementação desses classificadores, avaliou-se a eficácia de cada modelo e conjunto de features, e comparou-se os resultados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGIMz_rrvcXh"
   },
   "source": [
    "# Fonte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4Vp2sSLvhSd"
   },
   "source": [
    "[Kaggle - Cartola FC Dataset](https://www.kaggle.com/datasets/schiller/cartolafc)\n",
    "\n",
    "[Scikit Learn - LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n",
    "\n",
    "[Scikit Learn - DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "[Scikit Learn - RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "[Scikit Learn - SVM.SVC](https://scikit-learn.org/dev/modules/generated/sklearn.svm.SVC.html)\n",
    "\n",
    "[Scikit Learn - MLPClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neural_network.MLPClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6djMwuQF7_oc"
   },
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijcKQxSc7_od",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utPL4dTm7_od"
   },
   "source": [
    "Inicialmente obtém-se os dados para anáise. Assim, realiza-se o upload das bases previamente baixadas, através do link disponibilizado. Utilizou-se os seguintes arquivos da pasta:\n",
    "\n",
    "2017_scouts.csv, 2016_scouts.csv, 2017_atletas.csv, 2017_clubes.csv, 2017_partidas.csv, 2016_atletas.csv, 2016_clubes.csv, 2016_partidas.csv 2014_scouts.csv, 2015_scouts.csv, 2015_atletas.csv, 2015_clubes.csv, 2015_partidas.csv, 2014_atletas.csv, 2014_clubes.csv, 2014_partidas.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5ZozK55gFcX"
   },
   "outputs": [],
   "source": [
    "# Caminho para a pasta onde os arquivos estão\n",
    "path = 'C:/Users/gabriel.fuziama/Desktop/TG/archive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGprEo1HhTM-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Obtenção dos jogadores de 2014/2015/2016/2017\n",
    "scouts_2014 = pd.read_csv(path + '2014_scouts.csv')\n",
    "scouts_2015 = pd.read_csv(path + '2015_scouts.csv')\n",
    "scouts_2016 = pd.read_csv(path + '2016_scouts.csv')\n",
    "scouts_2017 = pd.read_csv(path + '2017_scouts.csv')\n",
    "\n",
    "# Obtenção dos dados das partidas de 2014/2015/2016/2017\n",
    "partidas_2014 = pd.read_csv(path + '2014_partidas.csv')\n",
    "partidas_2015 = pd.read_csv(path + '2015_partidas.csv')\n",
    "partidas_2016 = pd.read_csv(path + '2016_partidas.csv')\n",
    "partidas_2017 = pd.read_csv(path + '2017_partidas.csv')\n",
    "\n",
    "# Obtenção dos dados dos atletas de 2014/2015/2016/2017\n",
    "atletas_2014 = pd.read_csv(path + '2014_atletas.csv')\n",
    "atletas_2015 = pd.read_csv(path + '2015_atletas.csv')\n",
    "atletas_2016 = pd.read_csv(path + '2016_atletas.csv')\n",
    "atletas_2017 = pd.read_csv(path + '2017_atletas.csv')\n",
    "\n",
    "# Obtenção dos dados dos clubes de 2014/2015/2016/2017\n",
    "clubes_2014 = pd.read_csv(path + '2014_clubes.csv')\n",
    "clubes_2015 = pd.read_csv(path + '2015_clubes.csv')\n",
    "clubes_2016 = pd.read_csv(path + '2016_clubes.csv')\n",
    "clubes_2017 = pd.read_csv(path + '2017_clubes.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8MsSxWq7_of"
   },
   "source": [
    "Assim, pode-se observar o conteúdo de cada arquivo (exemplo):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06ypSp0-7_og"
   },
   "source": [
    "Nota-se que é necessário realizar um tratamento para obter um dataset completo e devidamente \"nomeado\" para cada partida de cada rodada dos campeonatos, descritos com os respectivos placares e times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaHFDtA-7_og"
   },
   "outputs": [],
   "source": [
    "# Agrupar informações das partidas e clubes (\"labels\")\n",
    "\n",
    "#Agrupa todos os times que jogaram nas temporadas 2014/2015/2016/2017\n",
    "import pandas as pd\n",
    "\n",
    "clubes = pd.concat([clubes_2014, clubes_2015, clubes_2016, clubes_2017], ignore_index=True)\n",
    "clubes = clubes.drop_duplicates(subset='nome')\n",
    "clubes\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2014\n",
    "df_2014 = partidas_2014.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2014 = df_2014.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2014 = df_2014[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2014['YEAR'] = '2014'\n",
    "df_2014.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2015\n",
    "df_2015 = partidas_2015.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2015 = df_2015.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2015 = df_2015[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2015['YEAR'] = '2015'\n",
    "df_2015.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2016\n",
    "df_2016 = partidas_2016.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2016 = df_2016.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2016 = df_2016[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2016['YEAR'] = '2016'\n",
    "df_2016.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2017\n",
    "df_2017 = partidas_2017.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2017 = df_2017.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2017 = df_2017[['rodada_id', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2017['YEAR'] = '2017'\n",
    "df_2017.rename(columns = {'nome': 'MANDANTE', 'rodada_id': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE','nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Join 2014/2015/2016/2017\n",
    "df0 = df_2016\n",
    "df = pd.concat([df0, df_2017, df_2014, df_2015], ignore_index=True)\n",
    "df = df[df['GOLS_MANDANTE'].notna()] # há alguns jogos sem informação (sem o placar)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBKZdBlY7_og"
   },
   "source": [
    "Após tratar os dados e consolidar todas as informações em um único dataset, calculou-se a o aproveitamento, quantidade de gols feitos e tomados, dentro e fora de casa (mandante e visitante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Dn-ttBs7_oh"
   },
   "outputs": [],
   "source": [
    "# Listagem do aproveitamento dentro e fora de casa para cada time durante o campeonato\n",
    "l_times_2014 = clubes_2014['nome'].tolist()\n",
    "l_times_2015 = clubes_2015['nome'].tolist()\n",
    "l_times_2016 = clubes_2016['nome'].tolist()\n",
    "l_times_2017 = clubes_2017['nome'].tolist()\n",
    "l_times = list(set(l_times_2014 + l_times_2015 + l_times_2016 + l_times_2017))\n",
    "l = []\n",
    "\n",
    "# Passa por cada jogo e analisa o resultado\n",
    "for i in range(len(l_times)):\n",
    "  j_m = 0\n",
    "  j_v = 0\n",
    "  v = 0\n",
    "  u = 0\n",
    "  g_m = 0\n",
    "  g_v = 0\n",
    "  g_m_t = 0\n",
    "  g_v_t = 0\n",
    "  # Analisa todos os jogos de um time como mandante e acumula a quantidade de vitórias, gols feitos e tomados\n",
    "  df_time = df[(df.MANDANTE == l_times[i])]\n",
    "  df_time.reset_index(inplace=True, drop=True)\n",
    "  for j in range(len(df_time)):\n",
    "    j_m += 1\n",
    "    g_m += df_time.at[j, 'GOLS_MANDANTE']\n",
    "    g_m_t += df_time.at[j, 'GOLS_VISITANTE']\n",
    "    if df_time.at[j, 'GOLS_MANDANTE'] > df_time.at[j, 'GOLS_VISITANTE']:\n",
    "      v += 1\n",
    "\n",
    "  # Analisa todos os jogos de um time como visitante e acumula a quantidade de vitórias, gols feitos e tomados\n",
    "  df_time = df[(df.VISITANTE == l_times[i])]\n",
    "  df_time.reset_index(inplace=True, drop=True)\n",
    "  for k in range(len(df_time)):\n",
    "    j_v += 1\n",
    "    g_v += df_time.at[k, 'GOLS_VISITANTE']\n",
    "    g_v_t += df_time.at[k, 'GOLS_MANDANTE']\n",
    "    if df_time.at[k, 'GOLS_MANDANTE'] < df_time.at[k, 'GOLS_VISITANTE']:\n",
    "      u += 1\n",
    "\n",
    "  # Cálculo do número de jogos por time\n",
    "  n_j = j_m + j_v\n",
    "\n",
    "  # Cálculo do número de vitórias\n",
    "  n_v = u + v\n",
    "\n",
    "  # Cálculo do aproveitamento como mandante (n° de vitórias/ quantidade de partidas)\n",
    "  ap_man = v/n_j\n",
    "\n",
    "  # Cálculo do aproveitamento como visitante (n° de vitórias/ quantidade de partidas)\n",
    "  ap_vis = u/n_j\n",
    "\n",
    "  # Cálculo do número de gols feitos\n",
    "  g_f = g_m + g_v\n",
    "\n",
    "  # Cálculo do número de gols tomados\n",
    "  g_t = g_m_t + g_v_t\n",
    "\n",
    "  # Cria uma lista para cada time seguido dos aproveitamentos (mandante e visitante,respectivamente)\n",
    "  l.append([l_times[i], n_j, n_v, ap_man, ap_vis, g_f, g_t])\n",
    "\n",
    "# DataFrame resultante\n",
    "df_ap = pd.DataFrame(l, columns=['Time', 'N°_jogos', 'N°_vitórias', 'Aproveitamento_Mandante', 'Aproveitamento_Visitante', 'Gols_feitos', 'Gols_tomados'])\n",
    "df_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4tf_Q9y7_oh"
   },
   "outputs": [],
   "source": [
    "# Inserindo as informações coletadas no dataframe \"partidas\" (df_f)\n",
    "\n",
    "df_f = pd.merge(df, df_ap, left_on='MANDANTE', right_on='Time')\n",
    "df_f = pd.merge(df_f, df_ap, left_on='VISITANTE', right_on='Time', suffixes=('_MANDANTE', '_VISITANTE'))\n",
    "\n",
    "# Definindo o resultado do jogo\n",
    "df_f['Resultado'] = np.where(df_f['GOLS_MANDANTE'] > df_f['GOLS_VISITANTE'], 'Vitória_MANDANTE', np.where(df_f['GOLS_MANDANTE'] < df_f['GOLS_VISITANTE'], 'Vitória_VISITANTE', 'Empate'))\n",
    "\n",
    "# Definindo pontuação do jogo\n",
    "df_f['Pontos Mandante'] = np.where(df_f['GOLS_MANDANTE'] > df_f['GOLS_VISITANTE'], 3, np.where(df_f['GOLS_MANDANTE'] < df_f['GOLS_VISITANTE'], 0, 1))\n",
    "df_f['Pontos Visitante'] = np.where(df_f['GOLS_MANDANTE'] > df_f['GOLS_VISITANTE'], 0, np.where(df_f['GOLS_MANDANTE'] < df_f['GOLS_VISITANTE'], 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oSRoIrEV47O"
   },
   "outputs": [],
   "source": [
    "# Ordenar o dataset\n",
    "df_f = df_f.sort_values(by=['YEAR', 'RODADA', 'MANDANTE', 'VISITANTE'])\n",
    "df_f = df_f.reset_index(drop=True)\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MJBCfXT6dFS"
   },
   "outputs": [],
   "source": [
    "# Bases \"scouts\"\n",
    "\n",
    "# Adicionar a coluna 'ano' nas bases dos scouts\n",
    "scouts_2014['ano'] = 2014\n",
    "scouts_2015['ano'] = 2015\n",
    "scouts_2016['ano'] = 2016\n",
    "scouts_2017['ano'] = 2017\n",
    "\n",
    "# Filtrar para considerar apenas os jogadores que participaram da partida (coluna participou é True)\n",
    "scouts_2014 = scouts_2014[scouts_2014['participou'] == True]\n",
    "scouts_2016 = scouts_2016[scouts_2016['participou'] == True]\n",
    "\n",
    "# Filtrar para considerar apenas os jogadores que participaram da partida (Pontuação diferente de 0 - não possue coluna 'participou')\n",
    "scouts_2015 = scouts_2015[scouts_2015['pontos_num'] != 0]\n",
    "scouts_2017 = scouts_2017[scouts_2017['pontos_num'] != 0]\n",
    "\n",
    "# Concatenar as bases de scouts\n",
    "scouts = pd.concat([scouts_2014, scouts_2015, scouts_2016, scouts_2017], ignore_index=True)\n",
    "\n",
    "# Retorna o nome do time em relação ao id\n",
    "scouts = scouts.set_index('clube_id')\n",
    "clubes = clubes.set_index('id')\n",
    "scouts = scouts.join(clubes['nome'], on='clube_id')\n",
    "\n",
    "scouts = scouts[scouts['rodada'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1r9pB16gyLHh"
   },
   "outputs": [],
   "source": [
    "### Pontuação média dos jogadores no ano ###\n",
    "\n",
    "# Função para calcular a média de pontos dos jogadores no ano\n",
    "def media_pontos_ano(nome, ano):\n",
    "    # Filtrar os jogos do ano\n",
    "    jogos = scouts[(scouts['nome'] == nome) & (scouts['ano'] == int(ano))]\n",
    "\n",
    "    # Calcular a média de pontos dos jogadores\n",
    "    media_pontos = jogos['pontos_num'].mean()\n",
    "    return media_pontos\n",
    "\n",
    "# Aplicar a função no dataframe df_f para calcular a média de pontos dos times mandante e visitante\n",
    "df_f['media_pontos_mandante'] = df_f.apply(lambda x: media_pontos_ano(x['MANDANTE'], x['YEAR']), axis=1)\n",
    "df_f['media_pontos_visitante'] = df_f.apply(lambda x: media_pontos_ano(x['VISITANTE'], x['YEAR']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNLK_VvYXUwR"
   },
   "outputs": [],
   "source": [
    "### Quantidade de Pontos nos Confrontos Diretos Anteriores ###\n",
    "\n",
    "# Função para calcular a quantidade de pontos dos confrontos diretos anteriores\n",
    "def pontos_confronto(time_1, time_2, ano, index_atual):\n",
    "    # Filtrar os confrontos diretos anteriores\n",
    "    jogos_m = df_f[(df_f['MANDANTE'] == time_1) & (df_f['VISITANTE'] == time_2) & (df_f['YEAR'] <= ano) & (df_f.index < index_atual)]\n",
    "    jogos_v = df_f[(df_f['MANDANTE'] == time_2) & (df_f['VISITANTE'] == time_1) & (df_f['YEAR'] <= ano) & (df_f.index < index_atual)]\n",
    "\n",
    "    # Calcular pontos\n",
    "    pontos_m = jogos_m['Pontos Mandante'].sum()\n",
    "    pontos_v = jogos_v['Pontos Visitante'].sum()\n",
    "\n",
    "    pontos = pontos_m + pontos_v\n",
    "    return pontos\n",
    "\n",
    "# Aplicar a função em cada linha do dataframe df_f para calcular a quntidade de pontos dos times mandante e visitante nos confrontos diretos anteriores\n",
    "df_f['Pontos Confronto Mandante'] = df_f.apply(lambda x: pontos_confronto(x['MANDANTE'], x['VISITANTE'], x['YEAR'], x.name), axis=1)\n",
    "df_f['Pontos Confronto Visitante'] = df_f.apply(lambda x: pontos_confronto(x['VISITANTE'], x['MANDANTE'], x['YEAR'], x.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2g0oWPvmNli"
   },
   "outputs": [],
   "source": [
    "### Quantidade de Pontos nas Últimas 3 Partidas ###\n",
    "\n",
    "# Função para calcular a quantidade de pontos dos times nas últimas 3 partidas (caso haja 3 partidas anteriores)\n",
    "def pontos_ult_3(time, ano, index_atual):\n",
    "    # Filtrar partidas anteriores\n",
    "    jogos_m = df_f[(df_f['MANDANTE'] == time) & (df_f['YEAR'] <= ano) & (df_f.index < index_atual)]\n",
    "    jogos_v = df_f[(df_f['VISITANTE'] == time) & (df_f['YEAR'] <= ano) & (df_f.index < index_atual)]\n",
    "    jogos_m['Pontos'] = jogos_m['Pontos Mandante']\n",
    "    jogos_v['Pontos'] = jogos_v['Pontos Visitante']\n",
    "    jogos = pd.concat([jogos_m, jogos_v])\n",
    "\n",
    "    # Ordenar por YEAR e RODADA, ambos em ordem decrescente\n",
    "    jogos = jogos.sort_values(by=['YEAR', 'RODADA'], ascending=[False, False])\n",
    "\n",
    "    # Selecionar as últimas 3 partidas\n",
    "    ultimos_jogos = jogos.head(3)\n",
    "\n",
    "    # Calcular a soma dos pontos\n",
    "    pontos = ultimos_jogos['Pontos'].sum()\n",
    "\n",
    "    return pontos\n",
    "\n",
    "# Aplicar a função em cada linha do dataframe df_f para calcular a quantidade de pontos dos times mandante e visitante nas últimas 3 partidas\n",
    "df_f['Pontos Ult 3 Mandante'] = df_f.apply(lambda x: pontos_ult_3(x['MANDANTE'], x['YEAR'], x.name), axis=1)\n",
    "df_f['Pontos Ult 3 Visitante'] = df_f.apply(lambda x: pontos_ult_3(x['VISITANTE'], x['YEAR'], x.name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udCMtE967_oh"
   },
   "source": [
    "Antes de iniciar a classificação e treinamentos, pode-se observar o dataset final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFM_gePPUxU6"
   },
   "outputs": [],
   "source": [
    "df_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Diu3JkBduNm1"
   },
   "source": [
    "## Teste das combinações de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7sV8Ws5XrmE"
   },
   "source": [
    "**Tota de 65532 combinações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import itertools\n",
    "\n",
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Lista de features\n",
    "feat = [\n",
    "    'Aproveitamento_Mandante_MANDANTE', 'Aproveitamento_Visitante_MANDANTE', \n",
    "    'Gols_feitos_MANDANTE', 'Gols_tomados_MANDANTE',\n",
    "    'Aproveitamento_Mandante_VISITANTE', 'Aproveitamento_Visitante_VISITANTE', \n",
    "    'Gols_feitos_VISITANTE', 'Gols_tomados_VISITANTE',\n",
    "    'media_pontos_mandante', 'media_pontos_visitante', \n",
    "    'Pontos Confronto Mandante', 'Pontos Confronto Visitante', \n",
    "    'Pontos Ult 3 Mandante', 'Pontos Ult 3 Visitante'\n",
    "]\n",
    "\n",
    "# Função para analisar combinações de features para um único modelo\n",
    "def analisar_modelo(modelo, nome_modelo, feat, df_f, le):\n",
    "    print(f\"Analisando modelo: {nome_modelo}\")\n",
    "    results = []\n",
    "    i = 0\n",
    "    \n",
    "    for r in range(1, len(feat) + 1):\n",
    "        for feat_comb in itertools.combinations(feat, r):\n",
    "            X = df_f[list(feat_comb)]\n",
    "            y = le.fit_transform(df_f['Resultado'])\n",
    "\n",
    "            # Divisão dos dados em treino e teste\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Padronizando as features para LogisticRegression, SVM e MLP\n",
    "            if nome_modelo in ['Logistic Regression', 'SVM', 'MLP']:\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "                \n",
    "            # Treinando o modelo\n",
    "            modelo.fit(X_train, y_train)\n",
    "\n",
    "            # Prevendo no conjunto de teste\n",
    "            y_pred = modelo.predict(X_test)\n",
    "\n",
    "            # Calculando a acurácia\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            i += 1\n",
    "\n",
    "            # Armazenando os resultados\n",
    "            results.append({'Modelo': nome_modelo, 'Features': feat_comb, 'Num_Features': len(feat_comb), 'Accuracy': accuracy, 'F1-Score': f1})\n",
    "            print(f\"Teste {i}: {nome_modelo} com {len(feat_comb)} features. Acurácia: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos individuais\n",
    "modelos = [('Logistic Regression', LogisticRegression(\n",
    "        multi_class='multinomial', \n",
    "        solver='lbfgs', \n",
    "        max_iter=500, \n",
    "        C=1.0, \n",
    "        class_weight='balanced'\n",
    "    )),\n",
    "    ('Decision Tree', DecisionTreeClassifier(\n",
    "        max_depth=10, \n",
    "        min_samples_split=20, \n",
    "        min_samples_leaf=10, \n",
    "        random_state=42, \n",
    "        class_weight='balanced'\n",
    "    )),\n",
    "    ('Random Forest', RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        max_depth=10, \n",
    "        min_samples_split=20, \n",
    "        min_samples_leaf=10, \n",
    "        random_state=42, \n",
    "        class_weight='balanced'\n",
    "    )),\n",
    "    ('SVM', SVC(\n",
    "        kernel='rbf', \n",
    "        C=1.0, \n",
    "        gamma='scale', \n",
    "        random_state=42, \n",
    "        class_weight='balanced'\n",
    "    )),\n",
    "    ('MLP', MLPClassifier(\n",
    "        hidden_layer_sizes=(50, 30), \n",
    "        max_iter=500, \n",
    "        solver='adam', \n",
    "        alpha=0.0001, \n",
    "        random_state=42, \n",
    "        tol=1e-4\n",
    "    ))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrhuPDpm7_oi"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "df_logreg = analisar_modelo(modelos[0][1], modelos[0][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_logreg.to_csv('logreg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgRVbHJD7_oj"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "df_dectree = analisar_modelo(modelos[1][1], modelos[1][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dectree.to_csv('dectree.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn0333Ptesoo"
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "df_randfor = analisar_modelo(modelos[2][1], modelos[2][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randfor.to_csv('randfor.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjklrEBTtF_3"
   },
   "source": [
    "### SVM.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "df_svm = analisar_modelo(modelos[3][1], modelos[3][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svm.to_csv('svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLEss_sCt9f_"
   },
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "\n",
    "df_mlp = analisar_modelo(modelos[4][1], modelos[4][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp.to_csv('mlp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_OaNumNOvPkn",
    "FGIMz_rrvcXh",
    "D4I5IGn0vXy2",
    "bsTqFeBL0OW0",
    "p4SerQAq0Jgu",
    "du-9sQ_o0gx2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
