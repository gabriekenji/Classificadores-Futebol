{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OaNumNOvPkn"
   },
   "source": [
    "# Introdução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0g3zTO-vVl9"
   },
   "source": [
    "O mundo do futebol, um esporte globalmente aclamado, oferece vastas oportunidades para análises e insights valiosos por meio de técnicas avançadas de aprendizado de máquina. Neste projeto, explorou-se a aplicação dessas técnicas para analisar e classificar os resultados de partidas de futebol, com base em dados detalhados das temporadas de 2014 a 2017 obtidos através da plataforma \"Kaggle\".\n",
    "\n",
    "Os conjuntos de dados abrangentes incluem informações sobre jogadores, clubes e resultados de partidas, levando em consideração variáveis como gols marcados, aproveitamento como mandante e visitante, número de gols, entre outros fatores determinantes (features), calculados posteriormente. A ênfase recai na criação de dois classificadores distintos: um utilizando Regressão Logística e outro baseado em Árvores de Decisão. Esses modelos visam prever os resultados (classes) de partidas com base em padrões históricos.\n",
    "\n",
    "Ao longo da implementação desses classificadores, avaliou-se a eficácia de cada abordagem e comparou-se os resultados obtidos. A análise detalhada das matrizes de confusão proporcionará uma compreensão aprofundada do desempenho de cada modelo, contribuindo para insights significativos no contexto do futebol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGIMz_rrvcXh"
   },
   "source": [
    "# Fonte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4Vp2sSLvhSd"
   },
   "source": [
    "[Kaggle - Cartola FC Dataset](https://www.kaggle.com/datasets/schiller/cartolafc)\n",
    "\n",
    "[Scikit Learn - LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n",
    "\n",
    "[Scikit Learn - DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4I5IGn0vXy2"
   },
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsTqFeBL0OW0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJjOECjvy-FE"
   },
   "source": [
    "Inicialmente obtém-se os dados para anáise. Assim relaiza-se o upload das bases previamente baixadas, através do link disponibilizado. Utilizou-se os seguintes arquivos da pasta:\n",
    "\n",
    "2017_scouts.csv, 2016_scouts.csv, 2017_atletas.csv, 2017_clubes.csv, 2017_partidas.csv, 2016_atletas.csv, 2016_clubes.csv, 2016_partidas.csv 2014_scouts.csv, 2015_scouts.csv, 2015_atletas.csv, 2015_clubes.csv, 2015_partidas.csv, 2014_atletas.csv, 2014_clubes.csv, 2014_partidas.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "rwB5kQRpoFnZ",
    "outputId": "ab572f9c-869f-40f5-d429-7af2ed759346"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-9d_sE5nUwy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtenção dos jogadores de 2014/2015/2016/2017\n",
    "scouts_2014   = pd.read_csv((io.StringIO(uploaded['2014_scouts.csv'].decode('utf-8'))))\n",
    "scouts_2015   = pd.read_csv((io.StringIO(uploaded['2015_scouts.csv'].decode('utf-8'))))\n",
    "scouts_2016   = pd.read_csv((io.StringIO(uploaded['2016_scouts.csv'].decode('utf-8'))))\n",
    "scouts_2017   = pd.read_csv((io.StringIO(uploaded['2017_scouts.csv'].decode('utf-8'))))\n",
    "\n",
    "# Obtenção dos dados das patidas de 2014/2015/2016/2017\n",
    "partidas_2014 = pd.read_csv((io.StringIO(uploaded['2014_partidas.csv'].decode('utf-8'))))\n",
    "partidas_2015 = pd.read_csv((io.StringIO(uploaded['2015_partidas.csv'].decode('utf-8'))))\n",
    "partidas_2016 = pd.read_csv((io.StringIO(uploaded['2016_partidas.csv'].decode('utf-8'))))\n",
    "partidas_2017 = pd.read_csv((io.StringIO(uploaded['2017_partidas.csv'].decode('utf-8'))))\n",
    "\n",
    "# Obtenção dos dados dos atletas de 2014/2015/2016/2017\n",
    "atletas_2014  = pd.read_csv((io.StringIO(uploaded['2014_atletas.csv'].decode('utf-8'))))\n",
    "atletas_2015  = pd.read_csv((io.StringIO(uploaded['2015_atletas.csv'].decode('utf-8'))))\n",
    "atletas_2016  = pd.read_csv((io.StringIO(uploaded['2016_atletas.csv'].decode('utf-8'))))\n",
    "atletas_2017  = pd.read_csv((io.StringIO(uploaded['2017_atletas.csv'].decode('utf-8'))))\n",
    "\n",
    "# Obtenção dos dados dos clubes de 2014/2015/2016/2017\n",
    "clubes_2014   = pd.read_csv((io.StringIO(uploaded['2014_clubes.csv'].decode('utf-8'))))\n",
    "clubes_2015   = pd.read_csv((io.StringIO(uploaded['2015_clubes.csv'].decode('utf-8'))))\n",
    "clubes_2016   = pd.read_csv((io.StringIO(uploaded['2016_clubes.csv'].decode('utf-8'))))\n",
    "clubes_2017   = pd.read_csv((io.StringIO(uploaded['2017_clubes.csv'].decode('utf-8'))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yqaD22OD_Cn"
   },
   "source": [
    "Assim, pode-se observar o conteúdo de cada arquivo (exemplo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "2URoooIDTtkg",
    "outputId": "920d78ca-7469-428b-83b7-80a589b6432b"
   },
   "outputs": [],
   "source": [
    "# Exemplo para a base de \"scout\" (jogadores/ desempenho)\n",
    "scouts_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "cKeh_oHqUZiQ",
    "outputId": "fdda1e44-8435-4cc7-f395-7101b80a32a9"
   },
   "outputs": [],
   "source": [
    "# Exemplo para a base de partidas\n",
    "partidas_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "g_dBjM2-UlUO",
    "outputId": "5f3af398-e6f3-4535-d414-dc2c60306b0f"
   },
   "outputs": [],
   "source": [
    "# Exemplo para a base de atletas (clube/ posição)\n",
    "atletas_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "91THcegKUln7",
    "outputId": "20cd84ad-a317-42d1-bad2-6cff4da0c64d"
   },
   "outputs": [],
   "source": [
    "# Exemplo para a base de clubes\n",
    "clubes_2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXaH-_B4TuA4"
   },
   "source": [
    "Nota-se que é necessário realizar um tratamento para obter um dataset completo e devidamente \"nomeado\" para cada partida de cada rodada dos campeonatos, descritos com os respectivos placares e times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xEEiMMynUw0"
   },
   "outputs": [],
   "source": [
    "# Agrupar informações das partidas e clubes (\"labels\")\n",
    "\n",
    "#Agrupa todos os times que jogaram nas temporadas 2014/2015/2016/2017\n",
    "import pandas as pd\n",
    "\n",
    "clubes = pd.concat([clubes_2014, clubes_2015, clubes_2016, clubes_2017], ignore_index=True)\n",
    "clubes = clubes.drop_duplicates(subset='nome')\n",
    "clubes\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2014\n",
    "df_2014 = partidas_2014.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2014 = df_2014.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2014 = df_2014[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2014['YEAR'] = '2014'\n",
    "df_2014.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2015\n",
    "df_2015 = partidas_2015.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2015 = df_2015.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2015 = df_2015[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2015['YEAR'] = '2015'\n",
    "df_2015.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2016\n",
    "df_2016 = partidas_2016.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2016 = df_2016.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2016 = df_2016[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2016['YEAR'] = '2016'\n",
    "df_2016.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2017\n",
    "df_2017 = partidas_2017.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2017 = df_2017.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2017 = df_2017[['rodada_id', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2017['YEAR'] = '2017'\n",
    "df_2017.rename(columns = {'nome': 'MANDANTE', 'rodada_id': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE','nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Join 2014/2015/2016/2017\n",
    "df0 = df_2016\n",
    "df = pd.concat([df0, df_2017, df_2014, df_2015], ignore_index=True)\n",
    "df = df[df['GOLS_MANDANTE'].notna()] # há alguns jogos sem informação (sem o placar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNn7MkKCtem5"
   },
   "source": [
    "Após tratar os dados e consolidar todas as informações em um único dataset, calculou-se a o aproveitamento, quantidade de gols feitos e tomados, dentro e fora de casa (mandante e visitante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "id": "eiV63Cbqpwra",
    "outputId": "46aa70c6-6032-4701-f580-57bcfda6ab07"
   },
   "outputs": [],
   "source": [
    "# Listagem do aproveitamento dentro e fora de casa para cada time durante o campeonato\n",
    "l_times_2014 = clubes_2014['nome'].tolist()\n",
    "l_times_2015 = clubes_2015['nome'].tolist()\n",
    "l_times_2016 = clubes_2016['nome'].tolist()\n",
    "l_times_2017 = clubes_2017['nome'].tolist()\n",
    "l_times = list(set(l_times_2014 + l_times_2015 + l_times_2016 + l_times_2017))\n",
    "l = []\n",
    "\n",
    "# Passa por cada jogo e analisa o resultado\n",
    "for i in range(len(l_times)):\n",
    "  j_m = 0\n",
    "  j_v = 0\n",
    "  v = 0\n",
    "  u = 0\n",
    "  g_m = 0\n",
    "  g_v = 0\n",
    "  g_m_t = 0\n",
    "  g_v_t = 0\n",
    "  # Analisa todos os jogos de um time como mandante e acumula a quantidade de vitórias, gols feitos e tomados\n",
    "  df_time = df[(df.MANDANTE == l_times[i])]\n",
    "  df_time.reset_index(inplace=True, drop=True)\n",
    "  for j in range(len(df_time)):\n",
    "    j_m += 1\n",
    "    g_m += df_time.at[j, 'GOLS_MANDANTE']\n",
    "    g_m_t += df_time.at[j, 'GOLS_VISITANTE']\n",
    "    if df_time.at[j, 'GOLS_MANDANTE'] > df_time.at[j, 'GOLS_VISITANTE']:\n",
    "      v += 1\n",
    "\n",
    "  # Analisa todos os jogos de um time como visitante e acumula a quantidade de vitórias, gols feitos e tomados\n",
    "  df_time = df[(df.VISITANTE == l_times[i])]\n",
    "  df_time.reset_index(inplace=True, drop=True)\n",
    "  for k in range(len(df_time)):\n",
    "    j_v += 1\n",
    "    g_v += df_time.at[k, 'GOLS_VISITANTE']\n",
    "    g_v_t += df_time.at[k, 'GOLS_MANDANTE']\n",
    "    if df_time.at[k, 'GOLS_MANDANTE'] < df_time.at[k, 'GOLS_VISITANTE']:\n",
    "      u += 1\n",
    "\n",
    "  # Cálculo do número de jogos por time\n",
    "  n_j = j_m + j_v\n",
    "\n",
    "  # Cálculo do número de vitórias\n",
    "  n_v = u + v\n",
    "\n",
    "  # Cálculo do aproveitamento como mandante (n° de vitórias/ quantidade de partidas)\n",
    "  ap_man = v/n_j\n",
    "\n",
    "  # Cálculo do aproveitamento como visitante (n° de vitórias/ quantidade de partidas)\n",
    "  ap_vis = u/n_j\n",
    "\n",
    "  # Cálculo do número de gols feitos\n",
    "  g_f = g_m + g_v\n",
    "\n",
    "  # Cálculo do número de gols tomados\n",
    "  g_t = g_m_t + g_v_t\n",
    "\n",
    "  # Cria uma lista para cada time seguido dos aproveitamentos (mandante e visitante,respectivamente)\n",
    "  l.append([l_times[i], n_j, n_v, ap_man, ap_vis, g_f, g_t])\n",
    "\n",
    "# DataFrame resultante\n",
    "df_ap = pd.DataFrame(l, columns=['Time', 'N°_jogos', 'N°_vitórias', 'Aproveitamento_Mandante', 'Aproveitamento_Visitante', 'Gols_feitos', 'Gols_tomados'])\n",
    "df_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzhwqhnQzHPq"
   },
   "source": [
    "Tendo as características (features) a serem consideradas (df_ap) e os resultados dos jogos (df), pode-se combinar essas informações a fim de classificar cada partida e treinar este classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqjbGyl4zGxX"
   },
   "outputs": [],
   "source": [
    "# Juntando as informações das duas bases\n",
    "\n",
    "df_f = pd.merge(df, df_ap, left_on='MANDANTE', right_on='Time')\n",
    "df_f = pd.merge(df_f, df_ap, left_on='VISITANTE', right_on='Time', suffixes=('_MANDANTE', '_VISITANTE'))\n",
    "\n",
    "# Definindo o resultado do jogo\n",
    "df_f['Resultado'] = np.where(df_f['GOLS_MANDANTE'] > df_f['GOLS_VISITANTE'], 'Vitória_MANDANTE', np.where(df_f['GOLS_MANDANTE'] < df_f['GOLS_VISITANTE'], 'Vitória_VISITANTE', 'Empate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPTFTGw38n42"
   },
   "source": [
    "Antes de iniciar a classificação e treinamentos, pode-se observar o dataset final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "wEjuJnZn8v4X",
    "outputId": "6fcf424e-eab3-4e8b-f9a1-2e846be542d2"
   },
   "outputs": [],
   "source": [
    "df_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4SerQAq0Jgu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlBujiOwyrQh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Definição das features\n",
    "feat = ['Aproveitamento_Mandante_MANDANTE', 'Aproveitamento_Visitante_MANDANTE', 'Gols_feitos_MANDANTE', 'Gols_tomados_MANDANTE', 'Aproveitamento_Mandante_VISITANTE', 'Aproveitamento_Visitante_VISITANTE', 'Gols_feitos_VISITANTE', 'Gols_tomados_VISITANTE']\n",
    "\n",
    "# Divisão dos dados em treino e teste através do train_test_split\n",
    "X = df_f[feat]\n",
    "y = df_f['Resultado']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYpXXNhW29TV"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fk_-Myr9f5W"
   },
   "source": [
    "A Regressão Logística é uma técnica comumente empregada em aprendizado de máquina para resolver problemas de classificação binária. Ela é utilizada para prever se uma instância pertence a uma das duas classes possíveis.\n",
    "\n",
    "No contexto do código fornecido, a Regressão Logística é aplicada para antecipar o desfecho de um jogo de futebol, determinando se o time que joga em casa terá um resultado positivo ou negativo,, ou seja, está sendo considerado apenas vitória ou derrota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9qQgRT728Bc",
    "outputId": "c51ef2df-7840-4a11-86dc-12633cc6ce36"
   },
   "outputs": [],
   "source": [
    "# Treinando o modelo LogisticRegression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Desempenho do modelo LogisticRegression\n",
    "y_pred = log_reg.predict(X_test)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "r_class = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia: {ac:.2f}')\n",
    "print('Relatório de Classificação:\\n', r_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lW3TtU8G3HDU"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wl-0Ac2-6Z_"
   },
   "source": [
    "A Árvore de Decisão é uma ferramenta poderosa no campo de aprendizado de máquina, sendo utilizada no código fornecido para prever os resultados de partidas de futebol, especificamente, categorizando se um time mandante será vitorioso, derrotado ou se a partida resultará em empate (neste caso, está sendo considerado as três classes possíveis).\n",
    "\n",
    "Este modelo é especialmente útil para identificar padrões intricados nos dados, oferecendo ao mesmo tempo compreensibilidade ao ilustrar as escolhas feitas pelo modelo. Cada ponto de decisão na árvore (nó) reflete uma escolha fundamentada em uma característica específica, e os ramos delineiam as diversas consequências dessas decisões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WELJI982jmG",
    "outputId": "d6cf1b46-2d70-47d1-af65-8f94193d8fdc"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Treinando o modelo DecisionTree\n",
    "d_tree = DecisionTreeClassifier(random_state=42)\n",
    "d_tree.fit(X_train, y_train)\n",
    "\n",
    "# Desempenho do modelo DecisionTree\n",
    "y_pred_d_tree = d_tree.predict(X_test)\n",
    "ac_d_tree = accuracy_score(y_test, y_pred_d_tree)\n",
    "r_d_tree = classification_report(y_test, y_pred_d_tree)\n",
    "\n",
    "print(f'Acurácia: {ac_d_tree:.2f}')\n",
    "print(\"Relatório de Classificação:\\n\", r_d_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoTXhrpH5vaK"
   },
   "source": [
    "### Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "MiunLNmV4Shm",
    "outputId": "11fa2424-9613-41d6-d337-70050ee28d07"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matriz de confusão\n",
    "def plot_confusion_matrix(ax, y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax, vmin=0, vmax=100)  # Ajuste as escalas de cor aqui\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Previsão do Modelo')\n",
    "    ax.set_ylabel('Verdadeiro Resultado')\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Matriz de confusão para LogisticRegression\n",
    "plot_confusion_matrix(axs[0], y_test, y_pred, 'Matriz de Confusão - Regressão Logística')\n",
    "\n",
    "# Matriz de confusão para DecisionTree\n",
    "plot_confusion_matrix(axs[1], y_test, y_pred_decision_tree, 'Matriz de Confusão - Árvore de Decisão')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du-9sQ_o0gx2",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Análise dos resultados e conclusão (Primeira Versão)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPlImKrAlVsC"
   },
   "source": [
    "Analisando os resultados e matrizes obtidas pode-se concluir que ambos os classificadores obtiveram resultado razoável para o conjunto de dados e o contexto aplicado, visto que obtiveram uma acurácia de 55% e 60% (Regressão logística e Árvore de Decisão, respectivamente). Observando especificamente o primeiro modelo, pode-se notar que uma de suas limitações é o fato de analisar somente dois casos (classes) possíveis, a vitória do time mandante ou vitória do time visitante (derrota do time mandante), o que pode ofuscar e dificultar parte do treinamento e obtenção de um padrão. É possível notar, também, que para os casos de vitória do mandante, o classificador obeteve um desempenho consideraelmente excepcional, obtendo um recall de 96%, o que se distingue para o caso oposto com um recall de 24%. Agora, para o caso com melhor resultado, se desenvolveu o classificador através das três classes possíveis, acrescentando, então, a situação de \"Empate\". Além disso, seguindo o mesmo padrão do outro analisado, a árvore de decisões apresentou uma maior precisão para o caso mandante (68% de precisão e 73% de recall) do que para o caso visitante (52% de precisão e 42% de recall), revelando-se, então, mais difícil de se prever com as \"features\" disponíveis.\n",
    "\n",
    "Para finalizar, dessa forma, nota-se algumas características do contexto observado e melhorias possíveis para o código como: desenvolviemnto de outros modelos de classificação e adição de caracterísiticas (desempenho dos jogadores, histórico de confrontos, etc), assim como, a possibilidade de times apresentarem um menor volume de partidas, visto que há a questão do acesso e rebaixamento entre as séries do campeonato brasileiro. Além de reforçar que uma partida de futebol possui fatores externos à resultados diretos e estatísticas que influnciam diretamente o resultado de uma partida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6djMwuQF7_oc"
   },
   "source": [
    "# Código (2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijcKQxSc7_od",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utPL4dTm7_od"
   },
   "source": [
    "Inicialmente obtém-se os dados para anáise. Assim relaiza-se o upload das bases previamente baixadas, através do link disponibilizado. Utilizou-se os seguintes arquivos da pasta:\n",
    "\n",
    "2017_scouts.csv, 2016_scouts.csv, 2017_atletas.csv, 2017_clubes.csv, 2017_partidas.csv, 2016_atletas.csv, 2016_clubes.csv, 2016_partidas.csv 2014_scouts.csv, 2015_scouts.csv, 2015_atletas.csv, 2015_clubes.csv, 2015_partidas.csv, 2014_atletas.csv, 2014_clubes.csv, 2014_partidas.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5ZozK55gFcX"
   },
   "outputs": [],
   "source": [
    "# Caminho para a pasta onde os arquivos estão\n",
    "path = 'C:/Users/gabriel.fuziama/Desktop/TG/archive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGprEo1HhTM-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtenção dos jogadores de 2014/2015/2016/2017\n",
    "scouts_2014 = pd.read_csv(path + '2014_scouts.csv')\n",
    "scouts_2015 = pd.read_csv(path + '2015_scouts.csv')\n",
    "scouts_2016 = pd.read_csv(path + '2016_scouts.csv')\n",
    "scouts_2017 = pd.read_csv(path + '2017_scouts.csv')\n",
    "\n",
    "# Obtenção dos dados das partidas de 2014/2015/2016/2017\n",
    "partidas_2014 = pd.read_csv(path + '2014_partidas.csv')\n",
    "partidas_2015 = pd.read_csv(path + '2015_partidas.csv')\n",
    "partidas_2016 = pd.read_csv(path + '2016_partidas.csv')\n",
    "partidas_2017 = pd.read_csv(path + '2017_partidas.csv')\n",
    "\n",
    "# Obtenção dos dados dos atletas de 2014/2015/2016/2017\n",
    "atletas_2014 = pd.read_csv(path + '2014_atletas.csv')\n",
    "atletas_2015 = pd.read_csv(path + '2015_atletas.csv')\n",
    "atletas_2016 = pd.read_csv(path + '2016_atletas.csv')\n",
    "atletas_2017 = pd.read_csv(path + '2017_atletas.csv')\n",
    "\n",
    "# Obtenção dos dados dos clubes de 2014/2015/2016/2017\n",
    "clubes_2014 = pd.read_csv(path + '2014_clubes.csv')\n",
    "clubes_2015 = pd.read_csv(path + '2015_clubes.csv')\n",
    "clubes_2016 = pd.read_csv(path + '2016_clubes.csv')\n",
    "clubes_2017 = pd.read_csv(path + '2017_clubes.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8MsSxWq7_of"
   },
   "source": [
    "Assim, pode-se observar o conteúdo de cada arquivo (exemplo):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06ypSp0-7_og"
   },
   "source": [
    "Nota-se que é necessário realizar um tratamento para obter um dataset completo e devidamente \"nomeado\" para cada partida de cada rodada dos campeonatos, descritos com os respectivos placares e times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaHFDtA-7_og"
   },
   "outputs": [],
   "source": [
    "# Agrupar informações das partidas e clubes (\"labels\")\n",
    "\n",
    "#Agrupa todos os times que jogaram nas temporadas 2014/2015/2016/2017\n",
    "import pandas as pd\n",
    "\n",
    "clubes = pd.concat([clubes_2014, clubes_2015, clubes_2016, clubes_2017], ignore_index=True)\n",
    "clubes = clubes.drop_duplicates(subset='nome')\n",
    "clubes\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2014\n",
    "df_2014 = partidas_2014.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2014 = df_2014.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2014 = df_2014[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2014['YEAR'] = '2014'\n",
    "df_2014.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2015\n",
    "df_2015 = partidas_2015.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2015 = df_2015.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2015 = df_2015[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2015['YEAR'] = '2015'\n",
    "df_2015.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2016\n",
    "df_2016 = partidas_2016.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2016 = df_2016.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2016 = df_2016[['rodada', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2016['YEAR'] = '2016'\n",
    "df_2016.rename(columns = {'nome': 'MANDANTE', 'rodada': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE', 'nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Substitui os ids pelos nomes e resultados específicos para cada jogo de cada rodada no ano de 2017\n",
    "df_2017 = partidas_2017.set_index('clube_casa_id').join(clubes.set_index('id'), rsuffix='_casa')\n",
    "df_2017 = df_2017.set_index('clube_visitante_id').join(clubes.set_index('id'), rsuffix='_visitante')\n",
    "df_2017 = df_2017[['rodada_id', 'nome', 'placar_oficial_mandante', 'nome_visitante', 'placar_oficial_visitante']]\n",
    "df_2017['YEAR'] = '2017'\n",
    "df_2017.rename(columns = {'nome': 'MANDANTE', 'rodada_id': 'RODADA', 'placar_oficial_mandante': 'GOLS_MANDANTE','nome_visitante': 'VISITANTE', 'placar_oficial_visitante': 'GOLS_VISITANTE'}, inplace = True)\n",
    "\n",
    "# Join 2014/2015/2016/2017\n",
    "df0 = df_2016\n",
    "df = pd.concat([df0, df_2017, df_2014, df_2015], ignore_index=True)\n",
    "df = df[df['GOLS_MANDANTE'].notna()] # há alguns jogos sem informação (sem o placar)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBKZdBlY7_og"
   },
   "source": [
    "Após tratar os dados e consolidar todas as informações em um único dataset, calculou-se a o aproveitamento, quantidade de gols feitos e tomados, dentro e fora de casa (mandante e visitante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Dn-ttBs7_oh"
   },
   "outputs": [],
   "source": [
    "# Listagem do aproveitamento dentro e fora de casa para cada time durante o campeonato\n",
    "l_times_2014 = clubes_2014['nome'].tolist()\n",
    "l_times_2015 = clubes_2015['nome'].tolist()\n",
    "l_times_2016 = clubes_2016['nome'].tolist()\n",
    "l_times_2017 = clubes_2017['nome'].tolist()\n",
    "l_times = list(set(l_times_2014 + l_times_2015 + l_times_2016 + l_times_2017))\n",
    "l = []\n",
    "\n",
    "# Passa por cada jogo e analisa o resultado\n",
    "for i in range(len(l_times)):\n",
    "  j_m = 0\n",
    "  j_v = 0\n",
    "  v = 0\n",
    "  u = 0\n",
    "  g_m = 0\n",
    "  g_v = 0\n",
    "  g_m_t = 0\n",
    "  g_v_t = 0\n",
    "  # Analisa todos os jogos de um time como mandante e acumula a quantidade de vitórias, gols feitos e tomados\n",
    "  df_time = df[(df.MANDANTE == l_times[i])]\n",
    "  df_time.reset_index(inplace=True, drop=True)\n",
    "  for j in range(len(df_time)):\n",
    "    j_m += 1\n",
    "    g_m += df_time.at[j, 'GOLS_MANDANTE']\n",
    "    g_m_t += df_time.at[j, 'GOLS_VISITANTE']\n",
    "    if df_time.at[j, 'GOLS_MANDANTE'] > df_time.at[j, 'GOLS_VISITANTE']:\n",
    "      v += 1\n",
    "\n",
    "  # Analisa todos os jogos de um time como visitante e acumula a quantidade de vitórias, gols feitos e tomados\n",
    "  df_time = df[(df.VISITANTE == l_times[i])]\n",
    "  df_time.reset_index(inplace=True, drop=True)\n",
    "  for k in range(len(df_time)):\n",
    "    j_v += 1\n",
    "    g_v += df_time.at[k, 'GOLS_VISITANTE']\n",
    "    g_v_t += df_time.at[k, 'GOLS_MANDANTE']\n",
    "    if df_time.at[k, 'GOLS_MANDANTE'] < df_time.at[k, 'GOLS_VISITANTE']:\n",
    "      u += 1\n",
    "\n",
    "  # Cálculo do número de jogos por time\n",
    "  n_j = j_m + j_v\n",
    "\n",
    "  # Cálculo do número de vitórias\n",
    "  n_v = u + v\n",
    "\n",
    "  # Cálculo do aproveitamento como mandante (n° de vitórias/ quantidade de partidas)\n",
    "  ap_man = v/n_j\n",
    "\n",
    "  # Cálculo do aproveitamento como visitante (n° de vitórias/ quantidade de partidas)\n",
    "  ap_vis = u/n_j\n",
    "\n",
    "  # Cálculo do número de gols feitos\n",
    "  g_f = g_m + g_v\n",
    "\n",
    "  # Cálculo do número de gols tomados\n",
    "  g_t = g_m_t + g_v_t\n",
    "\n",
    "  # Cria uma lista para cada time seguido dos aproveitamentos (mandante e visitante,respectivamente)\n",
    "  l.append([l_times[i], n_j, n_v, ap_man, ap_vis, g_f, g_t])\n",
    "\n",
    "# DataFrame resultante\n",
    "df_ap = pd.DataFrame(l, columns=['Time', 'N°_jogos', 'N°_vitórias', 'Aproveitamento_Mandante', 'Aproveitamento_Visitante', 'Gols_feitos', 'Gols_tomados'])\n",
    "df_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx8pzIXv7_oh"
   },
   "source": [
    "Tendo as características (features) a serem consideradas (df_ap) e os resultados dos jogos (df), pode-se combinar essas informações a fim de classificar cada partida e treinar este classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4tf_Q9y7_oh"
   },
   "outputs": [],
   "source": [
    "# Juntando as informações das duas bases\n",
    "\n",
    "df_f = pd.merge(df, df_ap, left_on='MANDANTE', right_on='Time')\n",
    "df_f = pd.merge(df_f, df_ap, left_on='VISITANTE', right_on='Time', suffixes=('_MANDANTE', '_VISITANTE'))\n",
    "\n",
    "# Definindo o resultado do jogo\n",
    "df_f['Resultado'] = np.where(df_f['GOLS_MANDANTE'] > df_f['GOLS_VISITANTE'], 'Vitória_MANDANTE', np.where(df_f['GOLS_MANDANTE'] < df_f['GOLS_VISITANTE'], 'Vitória_VISITANTE', 'Empate'))\n",
    "\n",
    "# Definindo pontuação do jogo\n",
    "df_f['Pontos Mandante'] = np.where(df_f['GOLS_MANDANTE'] > df_f['GOLS_VISITANTE'], 3, np.where(df_f['GOLS_MANDANTE'] < df_f['GOLS_VISITANTE'], 0, 1))\n",
    "df_f['Pontos Visitante'] = np.where(df_f['GOLS_MANDANTE'] > df_f['GOLS_VISITANTE'], 0, np.where(df_f['GOLS_MANDANTE'] < df_f['GOLS_VISITANTE'], 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oSRoIrEV47O"
   },
   "outputs": [],
   "source": [
    "# Ordenar o dataset\n",
    "df_f = df_f.sort_values(by=['YEAR', 'RODADA', 'MANDANTE', 'VISITANTE'])\n",
    "df_f = df_f.reset_index(drop=True)\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MJBCfXT6dFS"
   },
   "outputs": [],
   "source": [
    "# Adicionar a coluna 'ano' nas bases dos scouts\n",
    "scouts_2014['ano'] = 2014\n",
    "scouts_2015['ano'] = 2015\n",
    "scouts_2016['ano'] = 2016\n",
    "scouts_2017['ano'] = 2017\n",
    "\n",
    "# Filtrar para considerar apenas os jogadores que participaram da partida (coluna participou é True)\n",
    "scouts_2014 = scouts_2014[scouts_2014['participou'] == True]\n",
    "scouts_2016 = scouts_2016[scouts_2016['participou'] == True]\n",
    "\n",
    "# Filtrar para considerar apenas os jogadores que participaram da partida (Pontuação diferente de 0 - não possue coluna 'participou')\n",
    "scouts_2015 = scouts_2015[scouts_2015['pontos_num'] != 0]\n",
    "scouts_2017 = scouts_2017[scouts_2017['pontos_num'] != 0]\n",
    "\n",
    "# Concatenar as bases de scouts\n",
    "scouts = pd.concat([scouts_2014, scouts_2015, scouts_2016, scouts_2017], ignore_index=True)\n",
    "\n",
    "# Retorna o nome do time em relação ao id\n",
    "scouts = scouts.set_index('clube_id')\n",
    "clubes = clubes.set_index('id')\n",
    "scouts = scouts.join(clubes['nome'], on='clube_id')\n",
    "\n",
    "scouts = scouts[scouts['rodada'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1r9pB16gyLHh"
   },
   "outputs": [],
   "source": [
    "### Pontuação média dos jogadores no ano ###\n",
    "\n",
    "# Função para calcular a média de pontos dos jogadores no ano\n",
    "def media_pontos_ano(nome, ano):\n",
    "    # Filtrar os jogos do ano\n",
    "    jogos = scouts[(scouts['nome'] == nome) & (scouts['ano'] == int(ano))]\n",
    "\n",
    "    # Calcular a média de pontos dos jogadores\n",
    "    media_pontos = jogos['pontos_num'].mean()\n",
    "    return media_pontos\n",
    "\n",
    "# Aplicar a função no dataframe df_f para calcular a média de pontos dos times mandante e visitante\n",
    "df_f['media_pontos_mandante'] = df_f.apply(lambda x: media_pontos_ano(x['MANDANTE'], x['YEAR']), axis=1)\n",
    "df_f['media_pontos_visitante'] = df_f.apply(lambda x: media_pontos_ano(x['VISITANTE'], x['YEAR']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNLK_VvYXUwR"
   },
   "outputs": [],
   "source": [
    "### Quantidade de Pontos nos Confrontos Diretos Anteriores ###\n",
    "\n",
    "# Função para calcular a quantidade de pontos dos confrontos diretos anteriores\n",
    "def pontos_confronto(time_1, time_2, ano, index_atual):\n",
    "    # Filtrar os confrontos diretos anteriores\n",
    "    jogos_m = df_f[(df_f['MANDANTE'] == time_1) & (df_f['VISITANTE'] == time_2) & (df_f['YEAR'] <= ano) & (df_f.index < index_atual)]\n",
    "    jogos_v = df_f[(df_f['MANDANTE'] == time_2) & (df_f['VISITANTE'] == time_1) & (df_f['YEAR'] <= ano) & (df_f.index < index_atual)]\n",
    "\n",
    "    # Calcular pontos\n",
    "    pontos_m = jogos_m['Pontos Mandante'].sum()\n",
    "    pontos_v = jogos_v['Pontos Visitante'].sum()\n",
    "\n",
    "    pontos = pontos_m + pontos_v\n",
    "    return pontos\n",
    "\n",
    "# Aplicar a função em cada linha do dataframe df_f para calcular a quntidade de pontos dos times mandante e visitante nos confrontos diretos anteriores\n",
    "df_f['Pontos Confronto Mandante'] = df_f.apply(lambda x: pontos_confronto(x['MANDANTE'], x['VISITANTE'], x['YEAR'], x.name), axis=1)\n",
    "df_f['Pontos Confronto Visitante'] = df_f.apply(lambda x: pontos_confronto(x['VISITANTE'], x['MANDANTE'], x['YEAR'], x.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2g0oWPvmNli"
   },
   "outputs": [],
   "source": [
    "### Quantidade de Pontos nas Últimas 3 Partidas ###\n",
    "\n",
    "# Função para calcular a quantidade de pontos dos times nas últimas 3 partidas (caso haja 3 partidas anteriores)\n",
    "def pontos_ult_3(time, ano, index_atual):\n",
    "    # Filtrar partidas anteriores\n",
    "    jogos_m = df_f[(df_f['MANDANTE'] == time) & (df_f['YEAR'] <= ano) & (df_f.index < index_atual)]\n",
    "    jogos_v = df_f[(df_f['VISITANTE'] == time) & (df_f['YEAR'] <= ano) & (df_f.index < index_atual)]\n",
    "    jogos_m['Pontos'] = jogos_m['Pontos Mandante']\n",
    "    jogos_v['Pontos'] = jogos_v['Pontos Visitante']\n",
    "    jogos = pd.concat([jogos_m, jogos_v])\n",
    "\n",
    "    # Ordenar por YEAR e RODADA, ambos em ordem decrescente\n",
    "    jogos = jogos.sort_values(by=['YEAR', 'RODADA'], ascending=[False, False])\n",
    "\n",
    "    # Selecionar as últimas 3 partidas\n",
    "    ultimos_jogos = jogos.head(3)\n",
    "\n",
    "    # Calcular a soma dos pontos\n",
    "    pontos = ultimos_jogos['Pontos'].sum()\n",
    "\n",
    "    return pontos\n",
    "\n",
    "# Aplicar a função em cada linha do dataframe df_f para calcular a quantidade de pontos dos times mandante e visitante nas últimas 3 partidas\n",
    "df_f['Pontos Ult 3 Mandante'] = df_f.apply(lambda x: pontos_ult_3(x['MANDANTE'], x['YEAR'], x.name), axis=1)\n",
    "df_f['Pontos Ult 3 Visitante'] = df_f.apply(lambda x: pontos_ult_3(x['VISITANTE'], x['YEAR'], x.name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udCMtE967_oh"
   },
   "source": [
    "Antes de iniciar a classificação e treinamentos, pode-se observar o dataset final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFM_gePPUxU6"
   },
   "outputs": [],
   "source": [
    "df_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdAjo8yy7_oi",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vrMrIRV7_oi"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Definição das features\n",
    "feat = ['Aproveitamento_Mandante_MANDANTE', 'Aproveitamento_Visitante_MANDANTE', 'Gols_feitos_MANDANTE', 'Gols_tomados_MANDANTE', 'Aproveitamento_Mandante_VISITANTE', 'Aproveitamento_Visitante_VISITANTE', 'Gols_feitos_VISITANTE', 'Gols_tomados_VISITANTE', 'media_pontos_mandante', 'media_pontos_visitante', 'Pontos Confronto Mandante', 'Pontos Confronto Visitante', 'Pontos Ult 3 Mandante', 'Pontos Ult 3 Visitante']\n",
    "#feat = ['Aproveitamento_Mandante_MANDANTE', 'Gols_feitos_VISITANTE']\n",
    "# Divisão dos dados em treino e teste através do train_test_split\n",
    "X = df_f[feat]\n",
    "y = le.fit_transform(df_f['Resultado'])\n",
    "\n",
    "# Convertendo a coluna de resultados para valores numéricos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrhuPDpm7_oi"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAbGiUh67_oi",
    "outputId": "bb6a241c-630f-4219-dbfa-5c112ab25aca"
   },
   "outputs": [],
   "source": [
    "# Treinando o modelo LogisticRegression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Desempenho do modelo LogisticRegression\n",
    "y_pred = log_reg.predict(X_test)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "r_class = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia: {ac:.2f}')\n",
    "print('Relatório de Classificação:\\n', r_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgRVbHJD7_oj"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LKQkXQ17_oj",
    "outputId": "7c045ca8-c90f-4dd3-9bc1-53bbef2739d9"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Treinando o modelo DecisionTree\n",
    "d_tree = DecisionTreeClassifier(random_state=42)\n",
    "d_tree.fit(X_train, y_train)\n",
    "\n",
    "# Desempenho do modelo DecisionTree\n",
    "y_pred_d_tree = d_tree.predict(X_test)\n",
    "ac_d_tree = accuracy_score(y_test, y_pred_d_tree)\n",
    "r_d_tree = classification_report(y_test, y_pred_d_tree)\n",
    "\n",
    "print(f'Acurácia: {ac_d_tree:.2f}')\n",
    "print(\"Relatório de Classificação:\\n\", r_d_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STJTr4-o7_oj"
   },
   "source": [
    "### Matriz de Confusão (Logistic Regression e Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "Y8_Iknav7_ok",
    "outputId": "6b7a0aab-d57c-4eee-a1a6-b07532ac9104"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matriz de confusão\n",
    "def plot_confusion_matrix(ax, y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax, vmin=0, vmax=100)  # Ajuste as escalas de cor aqui\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Previsão do Modelo')\n",
    "    ax.set_ylabel('Verdadeiro Resultado')\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Matriz de confusão para LogisticRegression\n",
    "plot_confusion_matrix(axs[0], y_test, y_pred, 'Matriz de Confusão - Regressão Logística')\n",
    "\n",
    "# Matriz de confusão para DecisionTree\n",
    "plot_confusion_matrix(axs[1], y_test, y_pred_d_tree, 'Matriz de Confusão - Árvore de Decisão')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjklrEBTtF_3"
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11bEO_g9tEpw"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Treino\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Desempenho\n",
    "ac_svm = accuracy_score(y_test, y_pred_svm)\n",
    "r_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f'Acurácia: {ac_svm:.2f}')\n",
    "print('Relatório de Classificação:\\n', r_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn0333Ptesoo"
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrKNaEHftzzq",
    "outputId": "c5bf04b1-2d05-4790-aff4-5b726282a326"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Treino\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Desempenho\n",
    "ac_rf = accuracy_score(y_test, y_pred_rf)\n",
    "r_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Acurácia: {ac_rf:.2f}')\n",
    "print('Relatório de Classificação:\\n', r_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLEss_sCt9f_"
   },
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGFhrkOPenAg",
    "outputId": "44f2b268-0600-4bb5-e1db-a081e8779b99"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='adam', verbose=10,  random_state=42,tol=0.000000001)\n",
    "\n",
    "# Treino\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "# Desempenho\n",
    "ac_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "r_mlp = classification_report(y_test, y_pred_mlp)\n",
    "\n",
    "print(f'Acurácia: {ac_mlp:.2f}')\n",
    "print('Relatório de Classificação:\\n', r_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAf_EOXmOuV4"
   },
   "source": [
    "### Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiGOG6M3OtGE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definição das features\n",
    "feat = ['Aproveitamento_Mandante_MANDANTE', 'Aproveitamento_Visitante_MANDANTE', 'Gols_feitos_MANDANTE', 'Gols_tomados_MANDANTE', 'Aproveitamento_Mandante_VISITANTE', 'Aproveitamento_Visitante_VISITANTE', 'Gols_feitos_VISITANTE', 'Gols_tomados_VISITANTE', 'media_pontos_mandante', 'media_pontos_visitante', 'Pontos Confronto Mandante', 'Pontos Confronto Visitante', 'Pontos Ult 3 Mandante', 'Pontos Ult 3 Visitante']\n",
    "\n",
    "X = df_f[feat]\n",
    "y = df_f['Resultado']\n",
    "\n",
    "# Número de folds\n",
    "num_folds = 5\n",
    "\n",
    "# Modelo de LogisticRegression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "scores_log_reg = cross_val_score(log_reg, X, y, cv=num_folds, scoring='accuracy')\n",
    "\n",
    "# Modelo de Árvore de Decisão\n",
    "d_tree = DecisionTreeClassifier(random_state=42)\n",
    "scores_d_tree = cross_val_score(d_tree, X, y, cv=num_folds, scoring='accuracy')\n",
    "\n",
    "# Resultados\n",
    "print(f'(Validação Cruzada) Regressão Logística - Acurácia média: {scores_log_reg.mean():.2f}')\n",
    "print(f'(Validação Cruzada) Árvore de Decisão - Acurácia média: {scores_d_tree.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Diu3JkBduNm1"
   },
   "source": [
    "## Teste das combinações de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8xPpZYewdcI"
   },
   "source": [
    "Serão em torno de 2047 combinações possíveis de features para cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7sV8Ws5XrmE"
   },
   "source": [
    "**65532 combinações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import itertools\n",
    "\n",
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Lista de features\n",
    "feat = [\n",
    "    'Aproveitamento_Mandante_MANDANTE', 'Aproveitamento_Visitante_MANDANTE', \n",
    "    'Gols_feitos_MANDANTE', 'Gols_tomados_MANDANTE',\n",
    "    'Aproveitamento_Mandante_VISITANTE', 'Aproveitamento_Visitante_VISITANTE', \n",
    "    'Gols_feitos_VISITANTE', 'Gols_tomados_VISITANTE',\n",
    "    'media_pontos_mandante', 'media_pontos_visitante', \n",
    "    'Pontos Confronto Mandante', 'Pontos Confronto Visitante', \n",
    "    'Pontos Ult 3 Mandante', 'Pontos Ult 3 Visitante'\n",
    "]\n",
    "\n",
    "# Função para analisar combinações de features para um único modelo\n",
    "def analisar_modelo(modelo, nome_modelo, feat, df_f, le):\n",
    "    print(f\"Analisando modelo: {nome_modelo}\")\n",
    "    results = []\n",
    "    i = 0\n",
    "    \n",
    "    for r in range(1, len(feat) + 1):\n",
    "        for feat_comb in itertools.combinations(feat, r):\n",
    "            X = df_f[list(feat_comb)]\n",
    "            y = le.fit_transform(df_f['Resultado'])\n",
    "\n",
    "            # Divisão dos dados em treino e teste\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Padronizando as features para LogisticRegression, SVM e MLP\n",
    "            if nome_modelo in ['Logistic Regression', 'SVM', 'MLP']:\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "                \n",
    "            # Treinando o modelo\n",
    "            modelo.fit(X_train, y_train)\n",
    "\n",
    "            # Prevendo no conjunto de teste\n",
    "            y_pred = modelo.predict(X_test)\n",
    "\n",
    "            # Calculando a acurácia\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            i += 1\n",
    "\n",
    "            # Armazenando os resultados\n",
    "            results.append({'Modelo': nome_modelo, 'Features': feat_comb, 'Num_Features': len(feat_comb), 'Accuracy': accuracy, 'F1-Score': f1})\n",
    "            print(f\"Teste {i}: {nome_modelo} com {len(feat_comb)} features. Acurácia: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos individuais\n",
    "modelos = [('Logistic Regression', LogisticRegression(\n",
    "        multi_class='multinomial', \n",
    "        solver='lbfgs', \n",
    "        max_iter=500, \n",
    "        C=1.0, \n",
    "        class_weight='balanced'\n",
    "    )),\n",
    "    ('Decision Tree', DecisionTreeClassifier(\n",
    "        max_depth=10, \n",
    "        min_samples_split=20, \n",
    "        min_samples_leaf=10, \n",
    "        random_state=42, \n",
    "        class_weight='balanced'\n",
    "    )),\n",
    "    ('Random Forest', RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        max_depth=10, \n",
    "        min_samples_split=20, \n",
    "        min_samples_leaf=10, \n",
    "        random_state=42, \n",
    "        class_weight='balanced'\n",
    "    )),\n",
    "    ('SVM', SVC(\n",
    "        kernel='rbf', \n",
    "        C=1.0, \n",
    "        gamma='scale', \n",
    "        random_state=42, \n",
    "        class_weight='balanced'\n",
    "    )),\n",
    "    ('MLP', MLPClassifier(\n",
    "        hidden_layer_sizes=(50, 30), \n",
    "        max_iter=500, \n",
    "        solver='adam', \n",
    "        alpha=0.0001, \n",
    "        random_state=42, \n",
    "        tol=1e-4\n",
    "    ))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "df_logreg = analisar_modelo(modelos[0][1], modelos[0][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_logreg.to_csv('logreg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "df_dectree = analisar_modelo(modelos[1][1], modelos[1][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dectree.to_csv('dectree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "df_randfor = analisar_modelo(modelos[2][1], modelos[2][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randfor.to_csv('randfor.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "df_svm = analisar_modelo(modelos[3][1], modelos[3][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svm.to_csv('svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "\n",
    "df_mlp = analisar_modelo(modelos[4][1], modelos[4][0], feat, df_f, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp.to_csv('mlp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_OaNumNOvPkn",
    "FGIMz_rrvcXh",
    "D4I5IGn0vXy2",
    "bsTqFeBL0OW0",
    "p4SerQAq0Jgu",
    "du-9sQ_o0gx2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
